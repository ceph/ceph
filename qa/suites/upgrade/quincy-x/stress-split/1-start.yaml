overrides:
  ceph:
    log-ignorelist:
      - \(POOL_APP_NOT_ENABLED\)
      - OSD_DOWN
      - mons down
      - mon down
      - MON_DOWN
      - out of quorum
      - PG_DEGRADED
      - Reduced data availability
      - Degraded data redundancy
      - OSDMAP_FLAGS
      - PG_AVAILABILITY
tasks:
- install:
    branch: quincy
    exclude_packages:
      - ceph-volume

- cephadm:
    image: quay.ceph.io/ceph-ci/ceph:quincy
    cephadm_branch: quincy
    cephadm_git_url: https://github.com/ceph/ceph
    conf:
      osd:
        #set config option for which cls modules are allowed to be loaded / used
        osd_class_load_list: "*"
        osd_class_default_list: "*"

- cephadm.shell:
    mon.a:
      - ceph fs volume create foo
      - ceph config set mon mon_warn_on_insecure_global_id_reclaim false --force
      - ceph config set mon mon_warn_on_insecure_global_id_reclaim_allowed false --force

- ceph.healthy:

- print: "**** upgrading first half of cluster, with stress ****"
- parallel:
    - first-half-tasks
    - first-half-sequence
- print: "**** done upgrading first half of cluster ****"

- ceph.healthy:

- print: "**** applying stress + thrashing to mixed-version cluster ****"

- parallel:
    - stress-tasks

- ceph.healthy:

- print: "**** finishing upgrade ****"
- parallel:
    - second-half-tasks
    - second-half-sequence

- ceph.healthy:


#################

first-half-sequence:
- cephadm.shell:
    env: [sha1]
    mon.a:
      - ceph config set mgr mgr/cephadm/daemon_cache_timeout 60
      - ceph config set global log_to_journald false --force

      - ceph orch upgrade start --image quay.ceph.io/ceph-ci/ceph:$sha1
      - ceph orch ps

      - echo wait for minority of mons to upgrade
      - while ! ceph mon versions | grep $sha1 && ceph orch upgrade status | jq '.in_progress' | grep true && ! ceph orch upgrade status | jq '.message' | grep Error; do sleep 2 ; done
      - ceph orch ps
      - ceph orch upgrade pause
      - sleep 60
      - ceph orch upgrade resume

      - echo wait for majority of mons to upgrade
      - "while ! ceph mon versions | grep $sha1 | egrep ': [23]' && ceph orch upgrade status | jq '.in_progress' | grep true && ! ceph orch upgrade status | jq '.message' | grep Error; do sleep 2 ; done"
      - ceph orch ps
      - ceph orch upgrade pause
      - sleep 60
      - ceph orch upgrade resume

      - echo wait for all mons to upgrade
      - "while ! ceph mon versions | grep $sha1 | grep ': 3' && ceph orch upgrade status | jq '.in_progress' | grep true && ! ceph orch upgrade status | jq '.message' | grep Error; do sleep 2 ; done"
      - ceph orch ps
      - ceph orch upgrade pause
      - sleep 60
      - ceph orch upgrade resume

      - echo wait for half of osds to upgrade
      - "while ! ceph osd versions | grep $sha1 | egrep ': [45678]' && ceph orch upgrade status | jq '.in_progress' | grep true && ! ceph orch upgrade status | jq '.message' | grep Error; do sleep 2 ; done"
      - ceph orch upgrade pause
      - ceph orch ps

      - ceph orch ps
      - ceph versions


#################

stress-tasks:
- thrashosds:
    timeout: 1200
    chance_pgnum_grow: 1
    chance_pgpnum_fix: 1
    chance_thrash_cluster_full: 0
    chance_thrash_pg_upmap: 0
    chance_thrash_pg_upmap_items: 0
    disable_objectstore_tool_tests: true
    chance_force_recovery: 0
    aggressive_pg_num_changes: false


#################

second-half-sequence:
  sequential:
    - cephadm.shell:
        env: [sha1]
        mon.a:
          - ceph orch upgrade resume
          - sleep 60

          - echo wait for upgrade to complete
          - while ceph orch upgrade status | jq '.in_progress' | grep true ; do ceph orch ps ; ceph versions ; sleep 30 ; done

          - echo upgrade complete
          - ceph orch ps
          - ceph versions
          - ceph versions | jq -e '.overall | length == 1'
          - ceph versions | jq -e '.overall | keys' | grep $sha1
